{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKDIbALCiZiqI557sskTLm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Implementing GPT-2 model:"],"metadata":{"id":"0E2YpdTCpy7p"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"7dAAg91EppyB","executionInfo":{"status":"ok","timestamp":1755138176685,"user_tz":-420,"elapsed":11,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"outputs":[],"source":["GPT_CONFIG_124M = {\n","  \"vocab_size\": 50257, # Vocabulary size\n","  \"context_length\": 1024, # Context length\n","  \"emb_dim\": 768, # Embedding dimension\n","  \"n_heads\": 12, # Number of attention heads\n","  \"n_layers\": 12, # Number of layers\n","  \"drop_rate\": 0.1, # Dropout rate\n","  \"qkv_bias\": False # Query-Key-Value bias\n","}"]},{"cell_type":"code","source":["import torch\n","from torch import nn"],"metadata":{"id":"eLCE-m1xqKS6","executionInfo":{"status":"ok","timestamp":1755138187231,"user_tz":-420,"elapsed":10544,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class DummyGPTModel(nn.Module):\n","  def __init__(self, cfg_map):\n","    super().__init__()\n","\n","    # embedding components\n","    self.emb_layer = nn.Embedding(cfg_map['vocab_size'], cfg_map['emb_dim'])\n","    self.pos_emb_layer = nn.Embedding(cfg_map['context_length'], cfg_map['emb_dim'])\n","\n","    # huh\n","    self.dropout = nn.Dropout(cfg_map['drop_rate'])\n","\n","    # transformer\n","    self.trfm_block = nn.Sequential(*[TransformerBlock(cfg_map) for i in range(cfg_map['n_layers'])])\n","\n","    self.final_norm = LayerNorm(cfg_map['emb_dim'])\n","\n","    # convert to logits\n","    self.out_head = nn.Linear(cfg_map['emb_dim'], cfg_map['vocab_size'], bias = False)\n","\n","  def forward(self, in_idx):\n","    batch_size, seq_len = in_idx.shape\n","    tok_embed = self.emb_layer(in_idx)\n","    pos_embed = self.pos_emb_layer(torch.arange(seq_len, device = in_idx.device))\n","    x = tok_embed + pos_embed\n","    x = self.dropout(x)\n","    x = self.trfm_block(x)\n","    x = self.final_norm(x)\n","\n","    logits = self.out_head(x)\n","\n","    return logits\n","\n","class TransformerBlock(nn.Module):\n","  def __init__(self, cfg_map):\n","    super().__init__()\n","    self.norm_1 = LayerNorm(cfg_map['emb_dim'])\n","    self.multihead_attention = MultiheadAttention(cfg_map['emb_dim'], cfg_map['emb_dim'], cfg_map['drop_rate'], cfg_map['context_length'], cfg_map['n_heads'])\n","    self.dropout = nn.Dropout(cfg_map['drop_rate'])\n","    self.norm_2 = LayerNorm(cfg_map['emb_dim'])\n","    self.ffw = FeedForward(cfg_map)\n","  def forward(self, x):\n","    shortcut_x  = x\n","    x = self.norm_1(x)\n","    x = self.multihead_attention(x)\n","    x = self.dropout(x)\n","    x = shortcut_x + x\n","\n","    shortcut_x = x\n","    x = self.norm_2(x)\n","    x = self.ffw(x)\n","    x = self.dropout(x)\n","    x = x + shortcut_x\n","    return x\n","\n","class LayerNorm(nn.Module):\n","  def __init__(self, emb_dim, eps=1e-5):\n","    super().__init__()\n","    self.epsilon = eps\n","\n","    # learnable params to tweak the layer norm\n","    self.scale = nn.Parameter(torch.ones(emb_dim))\n","    self.shift = nn.Parameter(torch.zeros(emb_dim))\n","\n","  def forward(self, x):\n","    mean = torch.mean(x, dim = -1, keepdim = True)\n","    var = torch.var(x, dim = -1, keepdim = True, correction = False)\n","    norm_x = (x - mean) / (var + self.epsilon)**0.5\n","    return self.scale * norm_x + self.shift\n","\n","class GELULayer(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","  def forward(self, x):\n","    return 0.5 * x * (1 + torch.tanh((2/torch.pi)**0.5 * (x + 0.044715 * x**3)))\n","\n","class FeedForward(nn.Module):\n","  def __init__(self, cfg):\n","    super().__init__()\n","    self.layers = nn.Sequential(\n","        nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']), # domain expansion\n","        GELULayer(), # just gelu for non-linear\n","        nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim']), # domain contraction\n","    )\n","\n","  def forward(self, x):\n","    return self.layers(x)\n","\n","class MultiheadAttention(nn.Module):\n","  def __init__(self, d_in, d_out, drop_out_rate, context_length, num_heads, ena_bias = False):\n","    super().__init__()\n","\n","    assert (d_out % num_heads == 0), \\\n","      \"d_out must be divisible by num_heads\"\n","\n","    self.d_in = d_in\n","    self.d_out = d_out\n","    self.num_heads = num_heads\n","    self.head_dim = self.d_out // self.num_heads\n","\n","    self.W_Q = nn.Linear(d_in, d_out, bias = ena_bias)\n","    self.W_K = nn.Linear(d_in, d_out, bias = ena_bias)\n","    self.W_V = nn.Linear(d_in, d_out, bias = ena_bias)\n","\n","    # projection?\n","    self.out_proj = nn.Linear(d_out, d_out)\n","\n","    self.drop_out_layer = nn.Dropout(drop_out_rate)\n","    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal = 1))\n","\n","  def forward(self, x):\n","\n","    batch, num_tokens, d_in = x.shape\n","\n","    queries = self.W_Q(x)\n","    keys = self.W_K(x)\n","    values = self.W_V(x)\n","\n","    queries = queries.view(batch, num_tokens, self.num_heads, self.head_dim)\n","    keys = keys.view(batch, num_tokens, self.num_heads, self.head_dim)\n","    values = values.view(batch, num_tokens, self.num_heads, self.head_dim)\n","\n","    queries = queries.transpose(1,2)\n","    keys = keys.transpose(1,2)\n","    values = values.transpose(1,2)\n","\n","    attention_score = queries @ keys.transpose(2, 3)\n","\n","    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n","    attention_score.masked_fill_(mask_bool, -torch.inf)\n","    attention_score = attention_score / self.head_dim**0.5\n","    attention_weight = torch.softmax(attention_score, dim = -1)\n","    attention_weight = self.drop_out_layer(attention_weight)\n","\n","    context_vectors = (attention_weight @ values).transpose(1, 2)\n","\n","    context_vectors = context_vectors.contiguous().view(batch, num_tokens, self.d_out)\n","\n","    # combs for learning relationship of head's results\n","    context_vectors = self.out_proj(context_vectors)\n","\n","    return context_vectors\n"],"metadata":{"id":"CxR991-tqGnZ","executionInfo":{"status":"ok","timestamp":1755138187283,"user_tz":-420,"elapsed":56,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# this block of code for demonstrating the shortcut connection procedure\n","class ExampleNeuralNetwork(nn.Module):\n","  def __init__(self, shortcut_connection, size_arr):\n","    super().__init__()\n","    self.shortcut_connection = shortcut_connection\n","    self.layers = nn.Sequential(\n","        nn.Linear(size_arr[0], size_arr[1], GELULayer()),\n","        nn.Linear(size_arr[1], size_arr[2], GELULayer()),\n","        nn.Linear(size_arr[2], size_arr[3], GELULayer()),\n","        nn.Linear(size_arr[3], size_arr[4], GELULayer()),\n","        nn.Linear(size_arr[4], size_arr[5], GELULayer())\n","    )\n","\n","  def forward(self, x):\n","    for layer in self.layers:\n","      x_out = layer(x)\n","\n","      if self.shortcut_connection and x.shape == x_out.shape:\n","        x = x_out + x\n","      else:\n","        x = x_out\n","    return x"],"metadata":{"id":"HqxKg5t3Nw0U","executionInfo":{"status":"ok","timestamp":1755138187317,"user_tz":-420,"elapsed":28,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def print_gradient(model, x):\n","  output = model(x)\n","  target = torch.tensor([[0.]])\n","\n","  loss = nn.MSELoss()\n","  loss = loss(output, target)\n","\n","  loss.backward()\n","\n","  for name, param in model.named_parameters():\n","    if 'weight' in name:\n","      print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"],"metadata":{"id":"j-CS6R_APPDs","executionInfo":{"status":"ok","timestamp":1755138187345,"user_tz":-420,"elapsed":18,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["size_arr = [3, 3, 3, 3, 3, 1]\n","sample_input = torch.tensor([[1., 0., -1.]])\n","\n","torch.manual_seed(42)\n","\n","model_without_connection = ExampleNeuralNetwork(shortcut_connection=False, size_arr = size_arr)\n","print_gradient(model_without_connection, sample_input)\n","\n","print(\"------------------------------------------------------------------------------------\")\n","\n","model_with_connection = ExampleNeuralNetwork(shortcut_connection=True, size_arr = size_arr)\n","print_gradient(model_with_connection, sample_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3S39JQ2rQeEN","executionInfo":{"status":"ok","timestamp":1755138187646,"user_tz":-420,"elapsed":283,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"3bed8cff-f1f1-4d07-b020-1ecae2738d5d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["layers.0.weight has gradient mean of 0.010758272372186184\n","layers.1.weight has gradient mean of 0.02833496779203415\n","layers.2.weight has gradient mean of 0.031643930822610855\n","layers.3.weight has gradient mean of 0.12355596572160721\n","layers.4.weight has gradient mean of 0.18377549946308136\n","------------------------------------------------------------------------------------\n","layers.0.weight has gradient mean of 0.08325278759002686\n","layers.1.weight has gradient mean of 0.02883332222700119\n","layers.2.weight has gradient mean of 0.06909593939781189\n","layers.3.weight has gradient mean of 0.13771231472492218\n","layers.4.weight has gradient mean of 1.082464575767517\n"]}]},{"cell_type":"code","source":["# this only for testing dumb gpt\n","import tiktoken\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","batch = []\n","\n","input_1 = \"hello, how are u?\"\n","input_2 = \"plato is drinking water.\"\n","\n","batch.append(torch.tensor(tokenizer.encode(input_1)))\n","batch.append(torch.tensor(tokenizer.encode(input_2)))\n","\n","batch = torch.stack(batch, dim = 0)\n","\n","print(batch)\n","\n","torch.manual_seed(123)\n","\n","dumb_gpt = DummyGPTModel(GPT_CONFIG_124M)\n","\n","logits = dumb_gpt(batch)\n","\n","logits\n","print(logits.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XBSyWOVy2Ts","executionInfo":{"status":"ok","timestamp":1755138190960,"user_tz":-420,"elapsed":3307,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"8392ec3f-310c-46fd-913c-8137f63c94a6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[31373,    11,   703,   389,   334,    30],\n","        [  489,  5549,   318,  7722,  1660,    13]])\n","torch.Size([2, 6, 50257])\n"]}]},{"cell_type":"code","source":["# testing normalization layer\n","torch.manual_seed(42)\n","toy_input = torch.randn(3, 10)\n","\n","print(\"Mean before normalize:\")\n","print(torch.mean(toy_input, dim = -1, keepdim = True))\n","\n","print(\"Var before normalize:\")\n","print(torch.var(toy_input, dim = -1, keepdim = True, correction = False))\n","\n","\n","norm_layer = LayerNorm(10)\n","norm_input = norm_layer(toy_input)\n","\n","print(\"Mean after normalize:\")\n","print(torch.mean(norm_input, dim = -1, keepdim = True))\n","\n","print(\"Var after normalize:\")\n","print(torch.var(norm_input, dim = -1, keepdim = True, correction = False))"],"metadata":{"id":"oQPV7U0szDrA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755138190988,"user_tz":-420,"elapsed":25,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"170af3b3-eacd-4675-9067-4f490a127918"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean before normalize:\n","tensor([[ 0.0902],\n","        [-0.6379],\n","        [-0.1798]])\n","Var before normalize:\n","tensor([[1.8933],\n","        [0.9988],\n","        [1.1437]])\n","Mean after normalize:\n","tensor([[ 0.0000e+00],\n","        [-2.5332e-08],\n","        [ 8.9407e-09]], grad_fn=<MeanBackward1>)\n","Var after normalize:\n","tensor([[1.0000],\n","        [1.0000],\n","        [1.0000]], grad_fn=<VarBackward0>)\n"]}]},{"cell_type":"code","source":["# testing feed forward layer\n","ffn = FeedForward(GPT_CONFIG_124M)\n","x = torch.rand(2, 3, 768) #1\n","out = ffn(x)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsFucQpmisiE","executionInfo":{"status":"ok","timestamp":1755138191048,"user_tz":-420,"elapsed":59,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"7a1adef7-cebd-4abf-cdc4-55122d3c40a2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 768])\n"]}]},{"cell_type":"code","source":["# testing transformer block\n","torch.manual_seed(123)\n","x = torch.rand(2, 4, 768) #1\n","block = TransformerBlock(GPT_CONFIG_124M)\n","output = block(x)\n","print(\"Input shape:\", x.shape)\n","print(\"Output shape:\", output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luYl9u2ulkwj","executionInfo":{"status":"ok","timestamp":1755138191142,"user_tz":-420,"elapsed":92,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"e83cd4a2-7c0e-4bdb-f34a-f02cab53ca51"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4, 768])\n","Output shape: torch.Size([2, 4, 768])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8CHVMEpJNpiJ"},"execution_count":null,"outputs":[]}]}