{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+R73DoyOL+pB+7UcKpdN5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"MZIlfzi2OMEB","executionInfo":{"status":"ok","timestamp":1754623591277,"user_tz":-420,"elapsed":7430,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"outputs":[],"source":["import torch\n","inputs = torch.tensor(\n","[[0.43, 0.15, 0.89], # Your (x^1)\n","[0.55, 0.87, 0.66], # journey (x^2)\n","[0.57, 0.85, 0.64], # starts (x^3)\n","[0.22, 0.58, 0.33], # with (x^4)\n","[0.77, 0.25, 0.10], # one (x^5)\n","[0.05, 0.80, 0.55]] # step (x^6)\n",")"]},{"cell_type":"code","source":["new_input = torch.stack((inputs, inputs), dim = 0)\n","new_input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znbFFBNfQCUc","executionInfo":{"status":"ok","timestamp":1754623591403,"user_tz":-420,"elapsed":123,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"2be0740f-98af-4497-8df7-b2c0774185af"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0.4300, 0.1500, 0.8900],\n","         [0.5500, 0.8700, 0.6600],\n","         [0.5700, 0.8500, 0.6400],\n","         [0.2200, 0.5800, 0.3300],\n","         [0.7700, 0.2500, 0.1000],\n","         [0.0500, 0.8000, 0.5500]],\n","\n","        [[0.4300, 0.1500, 0.8900],\n","         [0.5500, 0.8700, 0.6600],\n","         [0.5700, 0.8500, 0.6400],\n","         [0.2200, 0.5800, 0.3300],\n","         [0.7700, 0.2500, 0.1000],\n","         [0.0500, 0.8000, 0.5500]]])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# Single causual attention:"],"metadata":{"id":"yT2j3vVBiVWq"}},{"cell_type":"code","source":["from torch import nn"],"metadata":{"id":"oQE8zIwxQ6BA","executionInfo":{"status":"ok","timestamp":1754623591406,"user_tz":-420,"elapsed":1,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class CausualAttention(nn.Module):\n","  def __init__(self, dim_in, dim_out, context_length, drop_out_rate, ena_bias = False):\n","    super().__init__()\n","    self.W_Q =  nn.Linear(dim_in, dim_out, bias = ena_bias)\n","    self.W_K =  nn.Linear(dim_in, dim_out, bias = ena_bias)\n","    self.W_V =  nn.Linear(dim_in, dim_out, bias = ena_bias)\n","\n","    self.dropout_layer = nn.Dropout(drop_out_rate)\n","    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n","\n","  def forward(self, x):\n","\n","    batch, num_tokens, dim = x.shape\n","    queries = self.W_Q(x)\n","    keys = self.W_K(x)\n","    values = self.W_V(x)\n","\n","    attention_score = queries @ keys.transpose(1,2) # .transpose(1, 2) for transpose in each batch, '1' for the 2nd dim, '2' for the 3rd dim\n","\n","    attention_score.masked_fill_(\n","        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf\n","    )\n","\n","    attention_weight = torch.softmax(attention_score / keys.shape[-1] ** 0.5, dim = -1)\n","\n","    # dropout\n","    attention_weight = self.dropout_layer(attention_weight)\n","\n","    contexts = attention_weight @ values\n","\n","    return contexts\n","\n"],"metadata":{"id":"QNsQBaUSQHkr","executionInfo":{"status":"ok","timestamp":1754623591411,"user_tz":-420,"elapsed":2,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["ca = CausualAttention(3, 2, 6, 0.0)\n","cntx = ca.forward(new_input)\n","cntx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QK40wMIyQqye","executionInfo":{"status":"ok","timestamp":1754623591466,"user_tz":-420,"elapsed":53,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"9842a90f-0e98-48aa-aea6-37fb713b391f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.0361, -0.3012],\n","         [-0.0312, -0.2411],\n","         [-0.0332, -0.2184],\n","         [-0.0185, -0.1739],\n","         [-0.0648, -0.1729],\n","         [-0.0290, -0.1491]],\n","\n","        [[-0.0361, -0.3012],\n","         [-0.0312, -0.2411],\n","         [-0.0332, -0.2184],\n","         [-0.0185, -0.1739],\n","         [-0.0648, -0.1729],\n","         [-0.0290, -0.1491]]], grad_fn=<UnsafeViewBackward0>)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# Multihead attention (wrapper):"],"metadata":{"id":"rDdDBETriZ0k"}},{"cell_type":"code","source":["class MultiheadAttentionWrapper(nn.Module):\n","  def __init__(self, dim_in, dim_out, context_length, drop_out_rate, num_heads, ena_bias = False):\n","    super().__init__()\n","    self.heads = nn.ModuleList([CausualAttention(dim_in, dim_out, context_length, drop_out_rate, ena_bias) for i in range(num_heads)])\n","\n","  def forward(self, x):\n","    return torch.cat([head.forward(x) for head in self.heads], dim = -1)"],"metadata":{"id":"xx8aRgd1Y3Yq","executionInfo":{"status":"ok","timestamp":1754623591482,"user_tz":-420,"elapsed":14,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","mlha = MultiheadAttentionWrapper(dim_in = 3, dim_out=2, context_length=6, drop_out_rate=0.0, num_heads=3)\n","cnx = mlha.forward(new_input)\n","cnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QN0Q3n51jz9N","executionInfo":{"status":"ok","timestamp":1754623591490,"user_tz":-420,"elapsed":11,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"aa61746f-fd2c-4d14-8a1e-1cf46fb4e672"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.4519,  0.2216,  0.4772,  0.1063,  0.4566,  0.2729],\n","         [-0.5874,  0.0058,  0.5891,  0.3257,  0.5792,  0.3011],\n","         [-0.6300, -0.0632,  0.6202,  0.3860,  0.6249,  0.3102],\n","         [-0.5675, -0.0843,  0.5478,  0.3589,  0.5691,  0.2785],\n","         [-0.5526, -0.0981,  0.5321,  0.3428,  0.5543,  0.2520],\n","         [-0.5299, -0.1081,  0.5077,  0.3493,  0.5337,  0.2499]],\n","\n","        [[-0.4519,  0.2216,  0.4772,  0.1063,  0.4566,  0.2729],\n","         [-0.5874,  0.0058,  0.5891,  0.3257,  0.5792,  0.3011],\n","         [-0.6300, -0.0632,  0.6202,  0.3860,  0.6249,  0.3102],\n","         [-0.5675, -0.0843,  0.5478,  0.3589,  0.5691,  0.2785],\n","         [-0.5526, -0.0981,  0.5321,  0.3428,  0.5543,  0.2520],\n","         [-0.5299, -0.1081,  0.5077,  0.3493,  0.5337,  0.2499]]],\n","       grad_fn=<CatBackward0>)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# The real multihead attention:"],"metadata":{"id":"9f3mVQ5Ct7EK"}},{"cell_type":"code","source":["class MultiheadAttention(nn.Module):\n","  def __init__(self, d_in, d_out, num_heads, context_length, drop_out_rate, ena_bias = False):\n","    super().__init__()\n","\n","    # wtf syntax?\n","    assert (d_out % num_heads == 0), \\\n","      \"d_out must be divisible by num_heads\"\n","\n","    self.d_out = d_out\n","    self.num_heads = num_heads\n","    self.head_dim = self.d_out // self.num_heads\n","\n","    self.W_Q = nn.Linear(d_in, d_out, bias = ena_bias)\n","    self.W_K = nn.Linear(d_in, d_out, bias = ena_bias)\n","    self.W_V = nn.Linear(d_in, d_out, bias = ena_bias)\n","\n","    # projection?\n","    self.out_proj = nn.Linear(d_out, d_out)\n","\n","    self.drop_out_layer = nn.Dropout(drop_out_rate)\n","    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal = 1))\n","\n","  def forward(self, x):\n","    b, num_tokens, d_in = x.shape\n","\n","    queries = self.W_Q(x)\n","    keys = self.W_K(x)\n","    values = self.W_V(x)\n","\n","    queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n","    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n","    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n","\n","    queries = queries.transpose(1,2)\n","    keys = keys.transpose(1,2)\n","    values = values.transpose(1,2)\n","\n","    attention_score = queries @ keys.transpose(2, 3)\n","\n","    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n","    attention_score.masked_fill_(mask_bool, -torch.inf)\n","    attention_score = attention_score / self.head_dim**0.5\n","    attention_weight = torch.softmax(attention_score, dim = -1)\n","    attention_weight = self.drop_out_layer(attention_weight)\n","\n","    context_vectors = (attention_weight @ values).transpose(1, 2)\n","\n","    context_vectors = context_vectors.contiguous().view(b, num_tokens, self.d_out)\n","\n","    # combs for learning relationship of head's results\n","    context_vectors = self.out_proj(context_vectors)\n","\n","    return context_vectors\n"],"metadata":{"id":"UkUKQVrUj-OU","executionInfo":{"status":"ok","timestamp":1754625559521,"user_tz":-420,"elapsed":9,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","mlha = MultiheadAttention(d_in = 3, d_out=3, context_length = 6, drop_out_rate=0.0, num_heads=3)\n","cnx = mlha.forward(new_input)\n","cnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQMrk6qm0eaR","executionInfo":{"status":"ok","timestamp":1754625624527,"user_tz":-420,"elapsed":9,"user":{"displayName":"Công Nguyễn Đức","userId":"18003168473153234789"}},"outputId":"554379c8-a3d4-4f5b-df07-d32ef08bed42"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.0766,  0.0755, -0.0321],\n","         [ 0.0311,  0.1048, -0.0368],\n","         [ 0.0165,  0.1088, -0.0409],\n","         [-0.0470,  0.0841, -0.0825],\n","         [-0.1018,  0.0327, -0.1292],\n","         [-0.1060,  0.0508, -0.1246]],\n","\n","        [[ 0.0766,  0.0755, -0.0321],\n","         [ 0.0311,  0.1048, -0.0368],\n","         [ 0.0165,  0.1088, -0.0409],\n","         [-0.0470,  0.0841, -0.0825],\n","         [-0.1018,  0.0327, -0.1292],\n","         [-0.1060,  0.0508, -0.1246]]], grad_fn=<ViewBackward0>)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":[],"metadata":{"id":"O1gFfM7W0-PX"},"execution_count":null,"outputs":[]}]}